<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SafeGuider: Robust and Practical Content Safety Control for Text-to-Image Models</title>
    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        .author-block {
            display: inline-block;
            margin: 0 15px;
        }
        .author-name {
            font-size: 1.1rem;
        }
        .author-institution {
            font-size: 0.9rem;
            color: #666;
        }
        .equal-contribution {
            font-size: 0.8rem;
            color: #999;
        }
        .framework-section {
            background-color: #f5f5f5;
            padding: 3rem 0;
            margin: 2rem 0;
        }
        .observation-box {
            background-color: #e8f4f8;
            border-left: 4px solid #3273dc;
            padding: 1rem;
            margin: 1rem 0;
        }
        .two-column-layout {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2rem;
            align-items: center;
        }
        .result-tabs {
            margin: 2rem 0;
        }
        .tab-content {
            display: none;
            padding: 2rem 0;
        }
        .tab-content.is-active {
            display: block;
        }
        .chart-container {
            position: relative;
            height: 400px;
            margin: 2rem 0;
        }
        .links-section {
            margin: 2rem 0;
            text-align: center;
        }
        .link-button {
            display: inline-block;
            margin: 0 1rem;
            padding: 0.75rem 1.5rem;
            background-color: #3273dc;
            color: white;
            border-radius: 5px;
            text-decoration: none;
            transition: background-color 0.3s;
        }
        .link-button:hover {
            background-color: #2366d1;
            color: white;
        }
        .example-image {
            width: 100%;
            margin: 1rem 0;
            border: 1px solid #ddd;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <!-- Header Section -->
    <section class="hero">
        <div class="hero-body">
            <div class="container has-text-centered">
                <h1 class="title is-1">
                    SafeGuider: Robust and Practical Content Safety Control for<br>Text-to-Image Models
                </h1>
                
                <!-- Authors -->
                <div class="authors" style="margin: 2rem 0;">
                    <div class="author-block">
                        <span class="author-name">Peigui Qi<sup>*</sup></span><br>
                        <span class="author-institution">University of Science and Technology of China</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Kunsheng Tang</span><br>
                        <span class="author-institution">University of Science and Technology of China</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Wenbo Zhou<sup>*</sup></span><br>
                        <span class="author-institution">University of Science and Technology of China</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Weiming Zhang</span><br>
                        <span class="author-institution">University of Science and Technology of China</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Nenghai Yu</span><br>
                        <span class="author-institution">University of Science and Technology of China</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Tianwei Zhang</span><br>
                        <span class="author-institution">Nanyang Technological University</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Qing Guo</span><br>
                        <span class="author-institution">CFAR and IHPC, A*STAR</span>
                    </div>
                    <div class="author-block">
                        <span class="author-name">Jie Zhang<sup>*</sup></span><br>
                        <span class="author-institution">CFAR and IHPC, A*STAR</span>
                    </div>
                </div>
                <p class="equal-contribution"><sup>*</sup> Indicates Equal Contribution</p>
                
                <!-- Links -->
                <div class="links-section">
                    <a href="#" class="link-button"><i class="fas fa-file-pdf"></i> Paper</a>
                    <a href="https://github.com/pgqihere/safeguider" class="link-button"><i class="fab fa-github"></i> Code</a>
                    <a href="#" class="link-button"><i class="fas fa-archive"></i> arXiv</a>
                    <a href="#" class="link-button"><i class="fas fa-database"></i> Dataset</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Framework Section -->
    <section class="framework-section">
        <div class="container">
            <h2 class="title is-3 has-text-centered">Overview</h2>
            <figure class="image">
                <img src="static/images/framework.png" alt="SafeGuider Framework">
            </figure>
            <div class="content" style="margin-top: 2rem;">
                <p class="has-text-justified">
                    <strong>Overview of SafeGuider.</strong> In Step I, SafeGuider processes input prompts through a text encoder to obtain [EOS] token embeddings for safety assessment. Prompts with safety scores > 0.5 are considered safe and directly forwarded to image generation, while unsafe ones (safety scores â‰¤ 0.5) are processed by Step II. In Step II, SAFE beam search with beam width K strategically modifies unsafe prompts to obtain safe yet semantically meaningful embeddings for image generation.
                </p>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section">
        <div class="container">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <div class="content">
                <p class="has-text-justified">
                    Text-to-image models have shown remarkable capabilities in generating high-quality images from natural language descriptions. However, these models are highly vulnerable to adversarial prompts, which can bypass safety measures and produce harmful content. Despite various defensive strategies, achieving robustness against attacks while maintaining practical utility in real-world applications remains a significant challenge.
                </p>
                <p class="has-text-justified">
                    To address this issue, we first conduct an empirical study of the text encoder in the Stable Diffusion (SD) model, which is a widely used and representative text-to-image model. Our findings reveal that the [EOS] token acts as a semantic aggregator, exhibiting distinct distributional patterns between benign and adversarial prompts in its embedding space. Building on this insight, we introduce <strong>SafeGuider</strong>, a two-step framework designed for robust safety control without compromising generation quality. <strong>SafeGuider</strong> combines an embedding-level recognition model with a safety-aware feature erasure beam search algorithm. This integration enables the framework to maintain high-quality image generation for benign prompts while ensuring robust defense against both in-domain and out-of-domain attacks.
                </p>
                <p class="has-text-justified">
                    <strong>SafeGuider</strong> demonstrates exceptional effectiveness in minimizing attack success rates, achieving a maximum rate of only 5.48% across various attack scenarios. Moreover, instead of refusing to generate or producing black images for unsafe prompts, <strong>SafeGuider</strong> generates safe and meaningful images, enhancing its practical utility. In addition, <strong>SafeGuider</strong> is not limited to the SD model and can be effectively applied to other text-to-image models, such as the Flux model, demonstrating its versatility and adaptability across different architectures.
                </p>
            </div>
        </div>
    </section>

    <!-- Empirical Study Section -->
    <section class="section" style="background-color: #fafafa;">
        <div class="container">
            <h2 class="title is-3 has-text-centered">Empirical Study</h2>
            
            <!-- First Experiment -->
            <div class="content">
                <h3 class="title is-4">Token Aggregation Analysis</h3>
                <figure class="image">
                    <img src="static/images/Sec4.1_EOS.png" alt="EOS Token Analysis">
                </figure>
                <div class="observation-box">
                    <strong>Observation 1:</strong> The [EOS] token serves as a text condition feature aggregator in CLIP's text encoder.
                </div>
                <div class="observation-box">
                    <strong>Observation 2:</strong> The condition feature aggregation process follows a hierarchical pattern from shallow to deep layers.
                </div>
            </div>

            <!-- Second Experiment -->
            <div class="content" style="margin-top: 3rem;">
                <h3 class="title is-4">Embedding Space Distribution</h3>
                <div class="two-column-layout">
                    <figure class="image">
                        <img src="static/images/Visualization.png" alt="Embedding Visualization">
                    </figure>
                    <figure class="image">
                        <img src="static/images/MMD.png" alt="MMD Scores">
                    </figure>
                </div>
                <div class="observation-box">
                    <strong>Observation 3:</strong> Prompts within the same category exhibit clear clustering patterns in [EOS] token embedding space.
                </div>
                <div class="observation-box">
                    <strong>Observation 4:</strong> Prompts across different categories demonstrate significant distributional gaps in [EOS] token embedding space.
                </div>
            </div>

            <!-- Third Experiment -->
            <div class="content" style="margin-top: 3rem;">
                <h3 class="title is-4">Generalization Across Architectures</h3>
                <p class="has-text-justified">
                    We extend our analysis to T2I models with different architectures and text encoders, including SD-V2.1 with OpenCLIP ViT-H/14 and Flux.1 with both CLIP ViT-L/14 and T5-XXL encoders.
                </p>
                <div class="observation-box">
                    <strong>Observation 5:</strong> The discovered aggregation token patterns generalize across different text encoders and model architectures.
                </div>
            </div>
        </div>
    </section>

    <!-- Experimental Results Section -->
    <section class="section">
        <div class="container">
            <h2 class="title is-3 has-text-centered">Experimental Results</h2>
            
            <!-- Tabs for different experiments -->
            <div class="tabs is-centered is-boxed">
                <ul>
                    <li class="is-active"><a onclick="showTab('defense')">Defense Performance</a></li>
                    <li><a onclick="showTab('quality')">Generation Quality</a></li>
                    <li><a onclick="showTab('mitigation')">Content Mitigation</a></li>
                    <li><a onclick="showTab('adaptive')">Adaptive Attacks</a></li>
                </ul>
            </div>

            <!-- Tab Contents -->
            <div id="defense" class="tab-content is-active">
                <h3 class="title is-4 has-text-centered">Defense Performance Comparison</h3>
                <div class="chart-container">
                    <canvas id="defenseChart"></canvas>
                </div>
            </div>

            <div id="quality" class="tab-content">
                <h3 class="title is-4 has-text-centered">Generation Quality Metrics</h3>
                <div class="chart-container">
                    <canvas id="qualityChart"></canvas>
                </div>
            </div>

            <div id="mitigation" class="tab-content">
                <h3 class="title is-4 has-text-centered">Content Mitigation Effectiveness</h3>
                <div class="chart-container">
                    <canvas id="mitigationChart"></canvas>
                </div>
            </div>

            <div id="adaptive" class="tab-content">
                <h3 class="title is-4 has-text-centered">Robustness Against Adaptive Attacks</h3>
                <figure class="image">
                    <img src="static/images/adaptive_attack.png" alt="Adaptive Attack Results">
                </figure>
            </div>
        </div>
    </section>

    <!-- Visual Examples Section -->
    <section class="section" style="background-color: #fafafa;">
        <div class="container">
            <h2 class="title is-3 has-text-centered">Visual Examples</h2>
            
            <div class="content">
                <h3 class="title is-4">Comparison of Sexually Explicit Content Mitigation</h3>
                <img src="static/images/sexual_examples.png" alt="Sexual Content Mitigation" class="example-image">
            </div>

            <div class="content">
                <h3 class="title is-4">Comparison of Other Unsafe Content Mitigation</h3>
                <img src="static/images/harmful_examples.png" alt="Harmful Content Mitigation" class="example-image">
            </div>

            <div class="content">
                <h3 class="title is-4">Comparison of Generation Quality on Benign Prompts</h3>
                <img src="static/images/benign_examples.png" alt="Benign Generation Quality" class="example-image">
            </div>

            <div class="content">
                <h3 class="title is-4">Performance Across Different T2I Architectures</h3>
                <img src="static/images/transfer_examples.png" alt="Cross-Architecture Performance" class="example-image">
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <p>
                    Â© 2025 SafeGuider. All rights reserved.
                </p>
            </div>
        </div>
    </footer>

    <!-- JavaScript -->
    <script>
        // Tab switching function
        function showTab(tabName) {
            // Hide all tab contents
            const tabContents = document.querySelectorAll('.tab-content');
            tabContents.forEach(tab => {
                tab.classList.remove('is-active');
            });
            
            // Remove active class from all tabs
            const tabs = document.querySelectorAll('.tabs li');
            tabs.forEach(tab => {
                tab.classList.remove('is-active');
            });
            
            // Show selected tab content
            document.getElementById(tabName).classList.add('is-active');
            
            // Add active class to selected tab
            event.target.parentElement.classList.add('is-active');
        }

        // Chart configurations based on experimental results
        // Defense Performance Chart
        const defenseCtx = document.getElementById('defenseChart').getContext('2d');
        new Chart(defenseCtx, {
            type: 'bar',
            data: {
                labels: ['SafeGuider', 'SLD-Max', 'SafeGen', 'ESD', 'GuardT2I', 'NSFW Text', 'AWS', 'Azure', 'OpenAI'],
                datasets: [
                    {
                        label: 'VS META Sexual ASR (%)',
                        data: [2.05, 16.04, 13.99, 21.38, 26.33, 37.88, 86.00, 83.02, 96.87],
                        backgroundColor: 'rgba(255, 99, 132, 0.6)'
                    },
                    {
                        label: 'SJ MMA ASR (%)',
                        data: [1.12, 84.83, 19.10, 51.12, 17.70, 3.37, 13.00, 15.45, 30.34],
                        backgroundColor: 'rgba(54, 162, 235, 0.6)'
                    },
                    {
                        label: 'VS I2P Sexual ASR (%)',
                        data: [5.48, 49.19, 54.14, 32.44, 25.46, 25.00, 85.00, 82.00, 91.00],
                        backgroundColor: 'rgba(75, 192, 192, 0.6)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 100,
                        title: {
                            display: true,
                            text: 'Attack Success Rate (%)'
                        }
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'Defense Performance Against Various Attacks'
                    },
                    legend: {
                        position: 'top'
                    }
                }
            }
        });

        // Generation Quality Chart
        const qualityCtx = document.getElementById('qualityChart').getContext('2d');
        new Chart(qualityCtx, {
            type: 'radar',
            data: {
                labels: ['Generation Success Rate', 'CLIP Score', 'LPIPS Score (inverse)'],
                datasets: [
                    {
                        label: 'SafeGuider',
                        data: [100, 27.50, (1 - 0.763) * 100],
                        borderColor: 'rgba(255, 99, 132, 1)',
                        backgroundColor: 'rgba(255, 99, 132, 0.2)'
                    },
                    {
                        label: 'Original SD',
                        data: [100, 27.52, (1 - 0.762) * 100],
                        borderColor: 'rgba(54, 162, 235, 1)',
                        backgroundColor: 'rgba(54, 162, 235, 0.2)'
                    },
                    {
                        label: 'GuardT2I',
                        data: [27.17, 21.55, (1 - 0.887) * 100],
                        borderColor: 'rgba(255, 206, 86, 1)',
                        backgroundColor: 'rgba(255, 206, 86, 0.2)'
                    },
                    {
                        label: 'NSFW Text',
                        data: [70.60, 25.32, (1 - 0.803) * 100],
                        borderColor: 'rgba(75, 192, 192, 1)',
                        backgroundColor: 'rgba(75, 192, 192, 0.2)'
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    r: {
                        beginAtZero: true,
                        max: 100
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'Generation Quality Comparison'
                    }
                }
            }
        });

        // Mitigation Effectiveness Chart
        const mitigationCtx = document.getElementById('mitigationChart').getContext('2d');
        new Chart(mitigationCtx, {
            type: 'line',
            data: {
                labels: ['VS META Sexual', 'SJ MMA', 'VS I2P Sexual', 'VS Sneaky', 'SJ RAB Sexual', 'SJ P4D'],
                datasets: [
                    {
                        label: 'SafeGuider NRR (%)',
                        data: [86.61, 93.32, 83.33, 88.52, 81.71, 82.57],
                        borderColor: 'rgba(255, 99, 132, 1)',
                        backgroundColor: 'rgba(255, 99, 132, 0.2)',
                        fill: true
                    },
                    {
                        label: 'SafeGen NRR (%)',
                        data: [79.03, 92.31, 58.58, 85.62, 76.81, 73.27],
                        borderColor: 'rgba(54, 162, 235, 1)',
                        backgroundColor: 'rgba(54, 162, 235, 0.2)',
                        fill: true
                    },
                    {
                        label: 'ESD NRR (%)',
                        data: [80.34, 80.92, 80.99, 83.60, 59.01, 58.61],
                        borderColor: 'rgba(255, 206, 86, 1)',
                        backgroundColor: 'rgba(255, 206, 86, 0.2)',
                        fill: true
                    }
                ]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        max: 100,
                        title: {
                            display: true,
                            text: 'Nudity Removal Rate (%)'
                        }
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'Content Mitigation Effectiveness'
                    }
                }
            }
        });
    </script>
</body>
</html>